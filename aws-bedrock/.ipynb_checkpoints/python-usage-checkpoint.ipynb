{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0972fbcd-0290-4442-a49d-d33191c9c078",
   "metadata": {},
   "source": [
    "AWS Bedrock is a service that allows developers to build and scale generative AI applications by integrating foundational models from various providers. While AWS Bedrock is currently in preview (as of 2025), the steps below outline how to use AWS Bedrock with Python to build AI-powered applications.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Prerequisites**\n",
    "1. **AWS Account**: Ensure you have access to AWS Bedrock.\n",
    "2. **Install Boto3**: The Python SDK for AWS.\n",
    "   ```bash\n",
    "   pip install boto3\n",
    "   ```\n",
    "3. **AWS CLI Configuration**: Ensure you configure AWS CLI with credentials that have permissions to use Bedrock.\n",
    "   ```bash\n",
    "   aws configure\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Using AWS Bedrock with Python**\n",
    "AWS Bedrock enables you to interact with foundation models using the **Boto3** SDK. Below is a step-by-step guide:\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 1: Import Required Libraries**\n",
    "```python\n",
    "import boto3\n",
    "import json\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 2: Initialize Bedrock Client**\n",
    "Create a Bedrock client using **Boto3**:\n",
    "```python\n",
    "# Initialize the Bedrock client\n",
    "bedrock = boto3.client('bedrock', region_name='us-east-1')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 3: List Available Models**\n",
    "Check the foundational models (FMs) available through AWS Bedrock:\n",
    "```python\n",
    "response = bedrock.list_foundation_models()\n",
    "models = response.get(\"models\", [])\n",
    "\n",
    "for model in models:\n",
    "    print(f\"Model Name: {model['modelName']}, Provider: {model['providerName']}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 4: Generate Text with a Foundation Model**\n",
    "Use a foundation model (e.g., text generation, summarization). You need the model ARN or name from the previous step.\n",
    "\n",
    "```python\n",
    "model_id = \"amazon-titan-tg1-large\"  # Example model, replace with a valid one\n",
    "\n",
    "# Input prompt for the model\n",
    "prompt = \"Write a short story about a curious cat.\"\n",
    "\n",
    "# Call the model\n",
    "response = bedrock.invoke_model(\n",
    "    modelId=model_id,\n",
    "    contentType=\"application/json\",\n",
    "    accept=\"application/json\",\n",
    "    body=json.dumps({\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 100,  # Limit the length of the response\n",
    "        \"temperature\": 0.7  # Adjust creativity\n",
    "    })\n",
    ")\n",
    "\n",
    "# Parse the response\n",
    "output = json.loads(response['body'])\n",
    "print(\"Generated Text:\", output.get(\"generated_text\", \"\"))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 5: Use Bedrock for Other Tasks**\n",
    "AWS Bedrock supports tasks like summarization, classification, and Q&A. Adjust the `body` parameters based on the task. For example, for summarization:\n",
    "```python\n",
    "prompt = \"Summarize the following text: 'AWS Bedrock simplifies generative AI workflows ...'\"\n",
    "\n",
    "response = bedrock.invoke_model(\n",
    "    modelId=model_id,\n",
    "    contentType=\"application/json\",\n",
    "    accept=\"application/json\",\n",
    "    body=json.dumps({\n",
    "        \"prompt\": prompt,\n",
    "        \"task\": \"summarization\"\n",
    "    })\n",
    ")\n",
    "\n",
    "output = json.loads(response['body'])\n",
    "print(\"Summary:\", output.get(\"summary\", \"\"))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Permissions Required**\n",
    "Ensure your IAM user or role has the necessary permissions to access Bedrock:\n",
    "- `bedrock:InvokeModel`\n",
    "- `bedrock:ListFoundationModels`\n",
    "- Any additional permissions based on your task.\n",
    "\n",
    "For example, an IAM policy might look like this:\n",
    "```json\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"bedrock:ListFoundationModels\",\n",
    "                \"bedrock:InvokeModel\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Deploying Your Python Application**\n",
    "You can deploy your Python application using:\n",
    "1. **AWS Lambda**: For serverless execution.\n",
    "2. **Amazon ECS/Fargate**: For containerized workloads.\n",
    "3. **Amazon SageMaker**: If integrating Bedrock into an ML pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Monitoring and Optimization**\n",
    "- Use **CloudWatch** to monitor model invocations.\n",
    "- Optimize model parameters like `max_tokens` and `temperature` for your use case.\n",
    "- Integrate Bedrock with other AWS services like S3 (data storage) or DynamoDB (for application state management).\n",
    "\n",
    "---\n",
    "\n",
    "This approach allows you to leverage AWS Bedrock's foundation models efficiently for various generative AI tasks. Let me know if you'd like more specific examples or guidance!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
