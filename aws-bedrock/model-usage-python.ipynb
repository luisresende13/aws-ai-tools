{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1434eeb9-9372-44ce-b389-94869dccd8b7",
   "metadata": {},
   "source": [
    "# Test 'bedrock' and 'bedrock-runtime' Python SDKs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07196dc2-c07c-4955-8933-614bf786a706",
   "metadata": {},
   "source": [
    "# MISSING:\n",
    "- EXAMPLE FOR TOOL USE\n",
    "- EXAMPLE FOR ASYNC INVOCATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a7b516-0182-4a1e-9de9-34a08e05e3e9",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "The following actions are supported by Amazon Bedrock Runtime:\n",
    "- [ ] ApplyGuardrail\n",
    "- [x] Converse\n",
    "- [ ] ConverseStream\n",
    "- [ ] GetAsyncInvoke\n",
    "- [x] InvokeModel\n",
    "- [ ] InvokeModelWithResponseStream\n",
    "- [ ] ListAsyncInvokes\n",
    "- [ ] StartAsyncInvoke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22c83b-7a7b-425a-8b58-eabea36ebc10",
   "metadata": {},
   "source": [
    "### List Models\n",
    "\n",
    "- 'bedrock' client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "877cb31d-c8e9-4c68-bcda-51dc13d2ddd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 80 foundation models.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelArn</th>\n",
       "      <th>modelId</th>\n",
       "      <th>modelName</th>\n",
       "      <th>providerName</th>\n",
       "      <th>inputModalities</th>\n",
       "      <th>outputModalities</th>\n",
       "      <th>responseStreamingSupported</th>\n",
       "      <th>customizationsSupported</th>\n",
       "      <th>inferenceTypesSupported</th>\n",
       "      <th>modelLifecycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-tg1-large</td>\n",
       "      <td>Titan Text Large</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-image-generator-v1:0</td>\n",
       "      <td>Titan Image Generator G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-image-generator-v1</td>\n",
       "      <td>Titan Image Generator G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-image-generator-v2:0</td>\n",
       "      <td>Titan Image Generator G1 v2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[PROVISIONED, ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-text-premier-v1:0</td>\n",
       "      <td>Titan Text G1 - Premier</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            modelArn  \\\n",
       "0  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "1  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "2  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "3  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "4  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "\n",
       "                             modelId                    modelName  \\\n",
       "0             amazon.titan-tg1-large             Titan Text Large   \n",
       "1  amazon.titan-image-generator-v1:0     Titan Image Generator G1   \n",
       "2    amazon.titan-image-generator-v1     Titan Image Generator G1   \n",
       "3  amazon.titan-image-generator-v2:0  Titan Image Generator G1 v2   \n",
       "4     amazon.titan-text-premier-v1:0      Titan Text G1 - Premier   \n",
       "\n",
       "  providerName inputModalities outputModalities responseStreamingSupported  \\\n",
       "0       Amazon          [TEXT]           [TEXT]                       True   \n",
       "1       Amazon   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "2       Amazon   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "3       Amazon   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "4       Amazon          [TEXT]           [TEXT]                       True   \n",
       "\n",
       "  customizationsSupported   inferenceTypesSupported        modelLifecycle  \n",
       "0                      []               [ON_DEMAND]  {'status': 'ACTIVE'}  \n",
       "1           [FINE_TUNING]             [PROVISIONED]  {'status': 'ACTIVE'}  \n",
       "2                      []               [ON_DEMAND]  {'status': 'ACTIVE'}  \n",
       "3           [FINE_TUNING]  [PROVISIONED, ON_DEMAND]  {'status': 'ACTIVE'}  \n",
       "4                      []               [ON_DEMAND]  {'status': 'ACTIVE'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Lists the available Amazon Bedrock models in an AWS Region.\n",
    "\"\"\"\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "bedrock_client = boto3.client(service_name=\"bedrock\", region_name=\"us-east-1\")\n",
    "response = bedrock_client.list_foundation_models()\n",
    "\n",
    "models = response[\"modelSummaries\"]\n",
    "\n",
    "print(f\"Got {len(models)} foundation models.\\n\")\n",
    "display(pd.DataFrame(models).head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3901051-f3d9-45c5-8e92-f6d829f88c48",
   "metadata": {},
   "source": [
    "### Invoke Model\n",
    "\n",
    "- `invoke_model` method\n",
    "- 'bedrock-runtime' client\n",
    "- Single message as input and output.\n",
    "- Uses the native inference api of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66ed9e9f-ebfa-4722-9854-1d845b621004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A 'hello world' program is a basic computer program that outputs the message \"hello world\" to the console.\n"
     ]
    }
   ],
   "source": [
    "# Use the native inference API to send a text message to Amazon Titan Text G1 - Express.\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Create an Amazon Bedrock Runtime client.\n",
    "brt = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "# Set the model ID, e.g., Amazon Titan Text G1 - Express.\n",
    "model_id = \"amazon.titan-text-express-v1\"\n",
    "\n",
    "# Define the prompt for the model.\n",
    "prompt = \"Describe the purpose of a 'hello world' program in one line.\"\n",
    "\n",
    "# Format the request payload using the model's native structure.\n",
    "native_request = {\n",
    "    \"inputText\": prompt,\n",
    "    \"textGenerationConfig\": {\n",
    "        \"maxTokenCount\": 512,\n",
    "        \"temperature\": 0.5,\n",
    "        \"topP\": 0.9\n",
    "    },\n",
    "}\n",
    "\n",
    "# Convert the native request to JSON.\n",
    "request = json.dumps(native_request)\n",
    "\n",
    "try:\n",
    "    # Invoke the model with the request.\n",
    "    response = brt.invoke_model(modelId=model_id, body=request)\n",
    "\n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Decode the response body.\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "# Extract and print the response text.\n",
    "response_text = model_response[\"results\"][0][\"outputText\"]\n",
    "print(response_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d0781db-e994-4b73-91ce-08ecbb67ed84",
   "metadata": {},
   "source": [
    "---\n",
    "### Converse\n",
    "\n",
    "- `converse` method\n",
    "- 'bedrock-runtime' client\n",
    "- Allows multiple messages as input, outputs a single message.\n",
    "- Unified inference api across models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "835cdd04-f26b-46da-9f93-4dd476d50b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The purpose of a 'hello world' program is to demonstrate the basic functionality of a programming language or environment by printing the phrase 'Hello, World!' to the console.\n"
     ]
    }
   ],
   "source": [
    "# Use the Conversation API to send a text message to Amazon Titan Text G1 - Express.\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Create an Amazon Bedrock Runtime client.\n",
    "brt = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "# Set the model ID, e.g., Amazon Titan Text G1 - Express.\n",
    "model_id = \"amazon.titan-text-express-v1\"\n",
    "\n",
    "# Start a conversation with the user message.\n",
    "user_message = \"Describe the purpose of a 'hello world' program in one line.\"\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": user_message}],\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Send the message to the model, using a basic inference configuration.\n",
    "    response = brt.converse(\n",
    "        modelId=model_id,\n",
    "        messages=conversation,\n",
    "        inferenceConfig={\"maxTokens\": 512, \"temperature\": 0.5, \"topP\": 0.9},\n",
    "    )\n",
    "\n",
    "    # Extract and print the response text.\n",
    "    response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "    print(response_text)\n",
    "\n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
