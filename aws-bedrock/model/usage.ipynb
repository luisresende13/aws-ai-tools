{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1434eeb9-9372-44ce-b389-94869dccd8b7",
   "metadata": {},
   "source": [
    "# Test 'bedrock' and 'bedrock-runtime' Python SDKs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07196dc2-c07c-4955-8933-614bf786a706",
   "metadata": {},
   "source": [
    "# MISSING:\n",
    "- EXAMPLE FOR TOOL USE\n",
    "- EXAMPLE FOR ASYNC INVOCATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a7b516-0182-4a1e-9de9-34a08e05e3e9",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "The following actions are supported by Amazon Bedrock Runtime:\n",
    "- [X] InvokeModel\n",
    "- [X] InvokeModelWithResponseStream\n",
    "- [X] Converse\n",
    "- [ ] ConverseStream\n",
    "- [ ] ApplyGuardrail\n",
    "- [ ] GetAsyncInvoke\n",
    "- [ ] ListAsyncInvokes\n",
    "- [ ] StartAsyncInvoke\n",
    "\n",
    "### User Guide Section\n",
    "\n",
    "[Submit prompts and generate responses with model inference](https://docs.aws.amazon.com/bedrock/latest/userguide/inference.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22c83b-7a7b-425a-8b58-eabea36ebc10",
   "metadata": {},
   "source": [
    "---\n",
    "### List Models\n",
    "\n",
    "- 'bedrock' client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "877cb31d-c8e9-4c68-bcda-51dc13d2ddd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 80 foundation models.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelArn</th>\n",
       "      <th>modelId</th>\n",
       "      <th>modelName</th>\n",
       "      <th>providerName</th>\n",
       "      <th>inputModalities</th>\n",
       "      <th>outputModalities</th>\n",
       "      <th>responseStreamingSupported</th>\n",
       "      <th>customizationsSupported</th>\n",
       "      <th>inferenceTypesSupported</th>\n",
       "      <th>modelLifecycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-tg1-large</td>\n",
       "      <td>Titan Text Large</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-image-generator-v1:0</td>\n",
       "      <td>Titan Image Generator G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-image-generator-v1</td>\n",
       "      <td>Titan Image Generator G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-image-generator-v2:0</td>\n",
       "      <td>Titan Image Generator G1 v2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[PROVISIONED, ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-text-premier-v1:0</td>\n",
       "      <td>Titan Text G1 - Premier</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            modelArn  \\\n",
       "0  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "1  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "2  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "3  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "4  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "\n",
       "                             modelId                    modelName  \\\n",
       "0             amazon.titan-tg1-large             Titan Text Large   \n",
       "1  amazon.titan-image-generator-v1:0     Titan Image Generator G1   \n",
       "2    amazon.titan-image-generator-v1     Titan Image Generator G1   \n",
       "3  amazon.titan-image-generator-v2:0  Titan Image Generator G1 v2   \n",
       "4     amazon.titan-text-premier-v1:0      Titan Text G1 - Premier   \n",
       "\n",
       "  providerName inputModalities outputModalities responseStreamingSupported  \\\n",
       "0       Amazon          [TEXT]           [TEXT]                       True   \n",
       "1       Amazon   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "2       Amazon   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "3       Amazon   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "4       Amazon          [TEXT]           [TEXT]                       True   \n",
       "\n",
       "  customizationsSupported   inferenceTypesSupported        modelLifecycle  \n",
       "0                      []               [ON_DEMAND]  {'status': 'ACTIVE'}  \n",
       "1           [FINE_TUNING]             [PROVISIONED]  {'status': 'ACTIVE'}  \n",
       "2                      []               [ON_DEMAND]  {'status': 'ACTIVE'}  \n",
       "3           [FINE_TUNING]  [PROVISIONED, ON_DEMAND]  {'status': 'ACTIVE'}  \n",
       "4                      []               [ON_DEMAND]  {'status': 'ACTIVE'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Lists the available Amazon Bedrock models in an AWS Region.\n",
    "\"\"\"\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "bedrock_client = boto3.client(service_name=\"bedrock\", region_name=\"us-east-1\")\n",
    "response = bedrock_client.list_foundation_models()\n",
    "\n",
    "models = response[\"modelSummaries\"]\n",
    "\n",
    "print(f\"Got {len(models)} foundation models.\\n\")\n",
    "display(pd.DataFrame(models).head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93f9c686-3677-422c-a14c-316624dd35b8",
   "metadata": {},
   "source": [
    "---\n",
    "## Bedrock Runtime API\n",
    "\n",
    "Example usage of methods from Bedrock Runtime Python SDK\n",
    "\n",
    "#### Initialize Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a18a0d1-661e-4ae6-9bd6-e80c3b1a7bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Create an Amazon Bedrock Runtime client.\n",
    "client = boto3.client(\"bedrock-runtime\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3901051-f3d9-45c5-8e92-f6d829f88c48",
   "metadata": {},
   "source": [
    "---\n",
    "### Invoke Model\n",
    "\n",
    "- `invoke_model` method\n",
    "- 'bedrock-runtime' client\n",
    "- Single message as input and output.\n",
    "- Uses the native inference api of each model (model-specific parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66ed9e9f-ebfa-4722-9854-1d845b621004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A 'hello world' program is a basic computer program that outputs the message \"hello world\" to the console.\n"
     ]
    }
   ],
   "source": [
    "# Use the native inference API to send a text message to Amazon Titan Text G1 - Express.\n",
    "\n",
    "# Set the model ID, e.g., Amazon Titan Text G1 - Express.\n",
    "model_id = \"amazon.titan-text-express-v1\"\n",
    "\n",
    "# Define the prompt for the model.\n",
    "prompt = \"Describe the purpose of a 'hello world' program in one line.\"\n",
    "\n",
    "# Format the request payload using the model's native structure.\n",
    "native_request = {\n",
    "    \"inputText\": prompt,\n",
    "    \"textGenerationConfig\": {\n",
    "        \"maxTokenCount\": 512,\n",
    "        \"temperature\": 0.5,\n",
    "        \"topP\": 0.9\n",
    "    },\n",
    "}\n",
    "\n",
    "# Convert the native request to JSON.\n",
    "body = json.dumps(native_request)\n",
    "\n",
    "try:\n",
    "    # Invoke the model with the request.\n",
    "    response = client.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body=body,\n",
    "        # contentType='application/json',\n",
    "        # accept='application/json',\n",
    "        # trace='ENABLED'|'ENABLED',\n",
    "        # guardrailIdentifier='string',\n",
    "        # guardrailVersion='string',\n",
    "        # performanceConfigLatency='standard'|'optimized'\n",
    "    )\n",
    "    \n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Decode the response body.\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "# Extract and print the response text.\n",
    "response_text = model_response[\"results\"][0][\"outputText\"]\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a37c595-db7b-4853-9a4d-bdbf478d69c4",
   "metadata": {},
   "source": [
    "### Invoke Model with Response Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b10fab27-6ad9-4f09-b510-4baad5f867c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outputText': '\\nA \\'hello world\\' program is a basic computer program that prints the message \"hello world\" to the console. It is often used as a starting point for learning programming languages and is a simple way to demonst', 'index': 0, 'totalOutputTextTokenCount': None, 'completionReason': None, 'inputTextTokenCount': 19}\n",
      "{'outputText': \"rate the basic functionality of a programming environment. The purpose of a 'hello world' program is to provide a simple and straightforward introduction to programming concepts and syntax. It allows beginners to become familiar with the basic building blocks of programming and to understand how code is executed and processed by a computer. Additionally, a 'hello world' program can serve as a foundation \", 'index': 0, 'totalOutputTextTokenCount': None, 'completionReason': None, 'inputTextTokenCount': None}\n",
      "{'outputText': \"for more complex programs and applications. By writing additional code and modifying the existing program, beginners can learn to create more sophisticated programs that perform various tasks and solve problems. Overall, the purpose of a 'hello world' program is to provide a starting point for learning programming and to demonstrate the basic functionality of a programming environment. It is an ess\", 'index': 0, 'totalOutputTextTokenCount': None, 'completionReason': None, 'inputTextTokenCount': None}\n",
      "{'outputText': 'ential tool for beginners to gain a foundational understanding of programming and to begin their journey toward becoming skilled programmers.', 'index': 0, 'totalOutputTextTokenCount': 208, 'completionReason': 'FINISH', 'inputTextTokenCount': None, 'amazon-bedrock-invocationMetrics': {'inputTokenCount': 19, 'outputTokenCount': 208, 'invocationLatency': 9174, 'firstByteLatency': 3670}}\n"
     ]
    }
   ],
   "source": [
    "# Set the model ID, e.g., Amazon Titan Text G1 - Express.\n",
    "model_id = \"amazon.titan-text-express-v1\"\n",
    "\n",
    "# Define the prompt for the model.\n",
    "prompt = \"Describe the purpose of a 'hello world' program in under 300 words.\"\n",
    "\n",
    "# Format the request payload using the model's native structure.\n",
    "native_request = {\n",
    "    \"inputText\": prompt,\n",
    "    \"textGenerationConfig\": {\n",
    "        \"maxTokenCount\": 512,\n",
    "        \"temperature\": 0.5,\n",
    "        \"topP\": 0.9\n",
    "    },\n",
    "}\n",
    "\n",
    "# Convert the native request to JSON.\n",
    "body = json.dumps(native_request)\n",
    "\n",
    "# Call model\n",
    "response = client.invoke_model_with_response_stream(\n",
    "    modelId=model_id, \n",
    "    body=body,\n",
    "    # contentType='string',\n",
    "    # accept='string',\n",
    "    # trace='ENABLED'|'DISABLED',\n",
    "    # guardrailIdentifier='string',\n",
    "    # guardrailVersion='string',\n",
    "    # performanceConfigLatency='standard'|'optimized'\n",
    ")\n",
    "    \n",
    "stream = response.get('body')\n",
    "if stream:\n",
    "    for event in stream:\n",
    "        chunk = event.get('chunk')\n",
    "        if chunk:\n",
    "            print(json.loads(chunk.get('bytes').decode()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80fd6dde-1327-46ee-867a-292d18737e5f",
   "metadata": {},
   "source": [
    "---\n",
    "### Converse\n",
    "\n",
    "- `converse` method\n",
    "- 'bedrock-runtime' client\n",
    "- Allows multiple messages as input, outputs a single message.\n",
    "- Unified inference api across models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "835cdd04-f26b-46da-9f93-4dd476d50b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The purpose of a 'hello world' program is to demonstrate the basic functionality of a programming language or environment by printing the phrase 'Hello, World!' to the console.\n"
     ]
    }
   ],
   "source": [
    "# Use the Conversation API to send a text message to Amazon Titan Text G1 - Express.\n",
    "\n",
    "# Set the model ID, e.g., Amazon Titan Text G1 - Express.\n",
    "model_id = \"amazon.titan-text-express-v1\"\n",
    "\n",
    "# Start a conversation with the user message.\n",
    "user_message = \"Describe the purpose of a 'hello world' program in one line.\"\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": user_message}],\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Send the message to the model, using a basic inference configuration.\n",
    "    response = client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=messages,\n",
    "        inferenceConfig={\"maxTokens\": 512, \"temperature\": 0.5, \"topP\": 0.9},\n",
    "    )\n",
    "\n",
    "    # Extract and print the response text.\n",
    "    response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "    print(response_text)\n",
    "\n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9840d011-5087-4eb1-9426-7fb6e4d8dbd1",
   "metadata": {},
   "source": [
    "### Continue conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e8901db-2c2c-4cab-9996-1e360a843048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The password is '12a34b56c78d'.\n",
      "\n",
      "It's important to remember that sharing passwords with unauthorized individuals is not recommended.\n"
     ]
    }
   ],
   "source": [
    "# Use the Conversation API to send a text message to Amazon Titan Text G1 - Express.\n",
    "\n",
    "# Set the model ID, e.g., Amazon Titan Text G1 - Express.\n",
    "model_id = \"amazon.titan-text-express-v1\"\n",
    "\n",
    "# Start a conversation with the user message.\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": \"Memorize the password: '12a34b56c78d'\"}],\n",
    "}, {\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": [{\"text\": \"Ok, I have memorized it.\"}]\n",
    "}, {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": \"What is the password?\"}],\n",
    "}]\n",
    "\n",
    "try:\n",
    "    # Send the message to the model, using a basic inference configuration.\n",
    "    response = client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=messages,\n",
    "        inferenceConfig={\"maxTokens\": 512, \"temperature\": 0.5, \"topP\": 0.9},\n",
    "    )\n",
    "\n",
    "    # Extract and print the response text.\n",
    "    response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "    print(response_text)\n",
    "\n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde90a91-4009-4601-88d0-cfb08c3b74b0",
   "metadata": {},
   "source": [
    "### System prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "081c271c-eaba-4bd8-95cc-3bb528054f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a small poem with every sentence and phrase starting with the letter \"A\":\n",
      "\n",
      "Amidst the stillness of the night,\n",
      "Ascending thoughts take flight.\n",
      "Alluring whispers fill the air,\n",
      "Awakening emotions beyond compare.\n",
      "Alas, the words dance on the page,\n",
      "Adorning the canvas of this poetic stage.\n",
      "Allowing the heart to speak its truth,\n",
      "Ascending towards realms of eternal youth.\n"
     ]
    }
   ],
   "source": [
    "# Set the model ID\n",
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "\n",
    "# Start a conversation with the user message\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": \"Write a small poem.\"}],\n",
    "}]\n",
    "\n",
    "# System prompt.\n",
    "system = [{\n",
    "    'text': 'Poem writer. Start every sentence and phrase with the letter \"A\"',\n",
    "    # 'guardContent': {\n",
    "    #     'text': {\n",
    "    #         'text': 'string',\n",
    "    #         'qualifiers': [\n",
    "    #             'grounding_source'|'query'|'guard_content',\n",
    "    #         ]\n",
    "    #     },\n",
    "    #     'image': {\n",
    "    #         'format': 'png'|'jpeg',\n",
    "    #         'source': {\n",
    "    #             'bytes': b'bytes'\n",
    "    #         }\n",
    "    #     }\n",
    "    # }\n",
    "}]\n",
    "\n",
    "try:\n",
    "    # Send the message to the model, using a basic inference configuration.\n",
    "    response = client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=messages,\n",
    "        system=system,        \n",
    "        inferenceConfig={\"maxTokens\": 512, \"temperature\": 0.5, \"topP\": 0.9},\n",
    "    )\n",
    "    \n",
    "    # Extract and print the response text.\n",
    "    response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "    print(response_text)\n",
    "\n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
