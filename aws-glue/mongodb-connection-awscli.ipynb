{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f5cb06-8734-4cbd-804d-98d832d668e0",
   "metadata": {},
   "source": [
    "To convert the provided steps into command-line commands for use with AWS CLI, you can follow these instructions:\n",
    "\n",
    "### Prerequisites:\n",
    "1. **MongoDB Cluster**: Ensure you have a running MongoDB instance (either on-premises, in the cloud, or MongoDB Atlas).\n",
    "2. **AWS Glue Service**: You need access to AWS Glue and the necessary permissions to create resources such as connections, crawlers, jobs, etc.\n",
    "3. **MongoDB JDBC Driver**: You will need the appropriate MongoDB JDBC driver.\n",
    "\n",
    "### Step-by-Step Command-Line Instructions:\n",
    "\n",
    "#### 1. **Set Up MongoDB JDBC Connection** (via CLI)\n",
    "\n",
    "- **Download MongoDB JDBC Driver**: Download the JDBC driver (such as `mongodb-jdbc-2.2.1-all.jar`) from the MongoDB website or the appropriate source.\n",
    "\n",
    "- **Upload JDBC Driver to AWS S3**:\n",
    "\n",
    "  Assuming the file `mongodb-jdbc-2.2.1-all.jar` is downloaded to `C:\\Downloads`, use the AWS CLI to upload it to your S3 bucket:\n",
    "\n",
    "  1. **Create an S3 Bucket (if you don't have one)**:\n",
    "     ```bash\n",
    "     aws s3 mb s3://your-bucket-name\n",
    "     ```\n",
    "\n",
    "  2. **Upload JDBC Driver to S3**:\n",
    "     ```bash\n",
    "     aws s3 cp C:\\Downloads\\mongodb-jdbc-2.2.1-all.jar s3://your-bucket-name/glue-jdbc-drivers/\n",
    "     ```\n",
    "\n",
    "#### 2. **Create a Connection in AWS Glue** (via CLI)\n",
    "\n",
    "To create a connection in AWS Glue for MongoDB, you'll need to use the AWS Glue API. The connection will reference the MongoDB JDBC driver uploaded to S3.\n",
    "\n",
    "Create the json file:\n",
    "\n",
    "connection-mongo.json\n",
    "``` json\n",
    "{\n",
    "    \"Name\": \"mongodb-connection\",\n",
    "    \"ConnectionType\": \"JDBC\",\n",
    "    \"ConnectionProperties\": {\n",
    "        \"JDBC_CONNECTION_URL\": \"jdbc:mongodb+srv://<username>:<password>@<address>?retryWrites=true&w=majority\",\n",
    "        \"USERNAME\": \"Luis Resende\",\n",
    "        \"PASSWORD\": \"Oct@Vision\",\n",
    "        \"JDBC_DRIVER_JAR_URI\": \"s3://<bucket-name>glue-jdbc-drivers/mongodb-jdbc-2.2.1-all.jar\",\n",
    "        \"JDBC_DRIVER_CLASS_NAME\": \"mongodb.jdbc.MongoDriver\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Here’s a basic command to create the JDBC connection:\n",
    "\n",
    "```bash\n",
    "aws glue create-connection --connection-input file://connection-mongo.json\n",
    "```\n",
    "\n",
    "- Replace `<username>`, `<password>`, `<hostname>`, `<port>`, and `<database>` with your MongoDB connection details.\n",
    "\n",
    "#### 3. **Create a Glue Crawler** (via CLI)\n",
    "\n",
    "##### 3.1. **Creating a Glue Database**\n",
    "   You can create a Glue database via the AWS CLI or AWS Management Console.\n",
    "\n",
    "   **Create database input file**:\n",
    "``` json\n",
    "    {\"Name\": \"your-glue-database-name\"}\n",
    "```\n",
    "\n",
    "   **Using AWS CLI**:\n",
    "   ```bash\n",
    "   aws glue create-database --database-input file://mongodb-database.json\n",
    "   ```\n",
    "\n",
    "   Replace `your-glue-database-name` with the name you want for your Glue database (e.g., `mongo_db_catalog`).\n",
    "\n",
    "   **Using AWS Console**:\n",
    "   - Open the [AWS Glue Console](https://console.aws.amazon.com/glue).\n",
    "   - Go to **Databases** in the **Data Catalog** section.\n",
    "   - Click **Add database**.\n",
    "   - Enter a name for the database (e.g., `mongo_db_catalog`) and click **Create**.\n",
    "\n",
    "After you set up the connection, create a Glue crawler to detect the schema of the MongoDB collection:\n",
    "\n",
    "```bash\n",
    "aws glue create-crawler \\\n",
    "    --name \"mongodb-crawler\" \\\n",
    "    --role \"arn:aws:iam::your-account-id:role/your-glue-role\" \\\n",
    "    --database-name \"your-glue-database\" \\\n",
    "    --targets '{\"jdbcTargets\":[{\"connectionName\":\"mongodb-connection\",\"path\":\"<database-name>.<collection-name>\"}]}'\n",
    "```\n",
    "\n",
    "- Replace `<path-to-mongodb-collection>` with the appropriate path to your MongoDB data.\n",
    "- Ensure the IAM role (`your-glue-role`) has the required permissions.\n",
    "\n",
    "#### 4. **Create a Glue ETL Job** (via CLI)\n",
    "\n",
    "To create a Glue ETL job, you can use the `create-job` API. Below is a basic example of how to create a Glue ETL job that reads data from MongoDB and writes it to S3:\n",
    "\n",
    "```bash\n",
    "aws glue create-job \\\n",
    "    --name \"mongodb-etl-job\" \\\n",
    "    --role \"arn:aws:iam::your-account-id:role/your-glue-role\" \\\n",
    "    --command '{\"Name\": \"glueetl\", \"ScriptLocation\": \"s3://your-script-location/etl-script.py\"}' \\\n",
    "    --default-arguments '{\"--TempDir\": \"s3://your-temp-dir/\"}'\n",
    "```\n",
    "\n",
    "- The `ScriptLocation` is where your ETL script (written in Python or Scala) resides.\n",
    "- Update `your-temp-dir` to a valid S3 path for temporary files.\n",
    "\n",
    "#### 5. **Run the Glue Job** (via CLI)\n",
    "\n",
    "Once your Glue ETL job is created, you can start it by running the following command:\n",
    "\n",
    "```bash\n",
    "aws glue start-job-run --job-name \"mongodb-etl-job\"\n",
    "```\n",
    "\n",
    "#### Example Glue Script for MongoDB ETL (Python)\n",
    "\n",
    "Here’s an example of an ETL script you can use in AWS Glue to read data from MongoDB and load it into S3. Save the script as `etl-script.py` and upload it to an S3 bucket (referenced in the `ScriptLocation` when creating the job).\n",
    "\n",
    "```python\n",
    "import sys\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.context import SQLContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize GlueContext\n",
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "\n",
    "# Create a Glue DynamicFrame from MongoDB\n",
    "mongodb_options = {\n",
    "    \"uri\": \"mongodb://<username>:<password>@<hostname>:<port>/<database>\",\n",
    "    \"database\": \"<database_name>\",\n",
    "    \"collection\": \"<collection_name>\"\n",
    "}\n",
    "\n",
    "# Load data from MongoDB into DynamicFrame\n",
    "mongo_df = glueContext.create_dynamic_frame.from_options(\n",
    "    connection_type=\"mongo\",\n",
    "    connection_options=mongodb_options\n",
    ")\n",
    "\n",
    "# Convert DynamicFrame to DataFrame for processing\n",
    "df = mongo_df.toDF()\n",
    "\n",
    "# Perform some transformations (example)\n",
    "df_transformed = df.select(\"field1\", \"field2\", \"field3\")\n",
    "\n",
    "# Convert DataFrame back to DynamicFrame\n",
    "dynamic_frame_transformed = DynamicFrame.fromDF(df_transformed, glueContext, \"dynamic_frame_transformed\")\n",
    "\n",
    "# Write the data to S3\n",
    "output_path = \"s3://your-output-bucket/output-folder/\"\n",
    "glueContext.write_dynamic_frame.from_options(\n",
    "    dynamic_frame_transformed,\n",
    "    connection_type=\"s3\",\n",
    "    connection_options={\"path\": output_path},\n",
    "    format=\"parquet\"\n",
    ")\n",
    "```\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "- **Step 1**: Create an S3 bucket and upload the MongoDB JDBC driver.\n",
    "- **Step 2**: Use the `aws glue create-connection` command to configure the MongoDB JDBC connection.\n",
    "- **Step 3**: Set up a Glue crawler using the `aws glue create-crawler` command.\n",
    "- **Step 4**: Create an ETL job with `aws glue create-job` and provide your Python or Scala script.\n",
    "- **Step 5**: Run your Glue ETL job with `aws glue start-job-run`.\n",
    "\n",
    "These steps will enable you to connect AWS Glue with MongoDB and run ETL jobs for data processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
