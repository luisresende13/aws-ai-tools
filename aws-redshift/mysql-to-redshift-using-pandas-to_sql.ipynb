{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e9a2f8e-23ae-499a-8551-d0a43b1738d1",
   "metadata": {},
   "source": [
    "Okay, let's outline a Python script to migrate MariaDB tables to AWS Redshift Serverless. This is a relatively complex task, so we'll break it down and provide a comprehensive solution with explanations.\n",
    "\n",
    "**Key Challenges and Considerations:**\n",
    "\n",
    "*   **Data Transfer:** We need an efficient way to extract data from MariaDB and load it into Redshift.\n",
    "*   **Data Type Mapping:** MariaDB and Redshift have different data type systems. Careful mapping is crucial to avoid data loss or errors.\n",
    "*   **Schema Creation:** We'll need to create tables in Redshift that match the MariaDB schema.\n",
    "*   **Performance:** For large tables, we need to consider performance and optimize the data transfer process.\n",
    "*   **Credentials Management:** We'll need secure ways to handle credentials for both databases.\n",
    "*   **Error Handling:** Robust error handling is important for troubleshooting issues.\n",
    "*   **Scalability:** This script should be able to handle multiple tables.\n",
    "\n",
    "**Required Libraries:**\n",
    "\n",
    "You'll need to install these libraries using `pip install`:\n",
    "\n",
    "```bash\n",
    "pip install mysql-connector-python psycopg2-binary boto3 pandas sqlalchemy\n",
    "```\n",
    "\n",
    "**Python Script:**\n",
    "\n",
    "```python\n",
    "import mysql.connector\n",
    "import psycopg2\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Database Configuration (Load from environment)\n",
    "MARIADB_HOST = os.getenv(\"MARIADB_HOST\")\n",
    "MARIADB_USER = os.getenv(\"MARIADB_USER\")\n",
    "MARIADB_PASSWORD = os.getenv(\"MARIADB_PASSWORD\")\n",
    "MARIADB_DATABASE = os.getenv(\"MARIADB_DATABASE\")\n",
    "REDSHIFT_HOST = os.getenv(\"REDSHIFT_HOST\")\n",
    "REDSHIFT_USER = os.getenv(\"REDSHIFT_USER\")\n",
    "REDSHIFT_PASSWORD = os.getenv(\"REDSHIFT_PASSWORD\")\n",
    "REDSHIFT_DATABASE = os.getenv(\"REDSHIFT_DATABASE\")\n",
    "REDSHIFT_PORT = os.getenv(\"REDSHIFT_PORT\")\n",
    "\n",
    "# Other Settings\n",
    "CHUNK_SIZE = 10000  # Number of rows to fetch and insert at a time\n",
    "\n",
    "# Data type mapping\n",
    "DATA_TYPE_MAP = {\n",
    "    \"tinyint\": \"SMALLINT\",\n",
    "    \"smallint\": \"SMALLINT\",\n",
    "    \"mediumint\": \"INTEGER\",\n",
    "    \"int\": \"INTEGER\",\n",
    "    \"integer\": \"INTEGER\",\n",
    "    \"bigint\": \"BIGINT\",\n",
    "    \"float\": \"FLOAT\",\n",
    "    \"double\": \"DOUBLE PRECISION\",\n",
    "    \"decimal\": \"DECIMAL\",\n",
    "    \"date\": \"DATE\",\n",
    "    \"datetime\": \"TIMESTAMP\",\n",
    "    \"timestamp\": \"TIMESTAMP\",\n",
    "    \"time\": \"TIME\",\n",
    "    \"year\": \"SMALLINT\",\n",
    "    \"char\": \"CHAR\",\n",
    "    \"varchar\": \"VARCHAR\",\n",
    "    \"text\": \"TEXT\",\n",
    "    \"mediumtext\": \"TEXT\",\n",
    "    \"longtext\": \"TEXT\",\n",
    "    \"blob\": \"BYTEA\",\n",
    "    \"mediumblob\": \"BYTEA\",\n",
    "    \"longblob\": \"BYTEA\",\n",
    "    \"enum\": \"VARCHAR\",  # Handle enum as VARCHAR\n",
    "    \"set\": \"VARCHAR\",   # Handle set as VARCHAR\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def get_mariadb_connection():\n",
    "    \"\"\"Creates and returns a MariaDB connection.\"\"\"\n",
    "    try:\n",
    "        conn = mysql.connector.connect(\n",
    "            host=MARIADB_HOST,\n",
    "            user=MARIADB_USER,\n",
    "            password=MARIADB_PASSWORD,\n",
    "            database=MARIADB_DATABASE,\n",
    "        )\n",
    "        conn.autocommit = True\n",
    "        return conn\n",
    "    except mysql.connector.Error as err:\n",
    "        logging.error(f\"Error connecting to MariaDB: {err}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def get_redshift_engine():\n",
    "    \"\"\"Creates and returns a SQLAlchemy engine for Redshift.\"\"\"\n",
    "    try:\n",
    "      \n",
    "        redshift_uri = f\"postgresql+psycopg2://{REDSHIFT_USER}:{REDSHIFT_PASSWORD}@{REDSHIFT_HOST}:{REDSHIFT_PORT}/{REDSHIFT_DATABASE}\"\n",
    "        engine = create_engine(redshift_uri)\n",
    "        return engine\n",
    "    except SQLAlchemyError as e:\n",
    "        logging.error(f\"Error connecting to Redshift: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def get_mariadb_tables(conn):\n",
    "    \"\"\"Fetches a list of all tables in the MariaDB database.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SHOW TABLES\")\n",
    "    tables = [table[0] for table in cursor.fetchall()]\n",
    "    cursor.close()\n",
    "    return tables\n",
    "\n",
    "\n",
    "def get_mariadb_table_schema(conn, table_name):\n",
    "    \"\"\"Fetches the schema of a table from MariaDB.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"SHOW COLUMNS FROM `{table_name}`\")\n",
    "    columns = cursor.fetchall()\n",
    "    cursor.close()\n",
    "\n",
    "    schema = []\n",
    "    for column in columns:\n",
    "      col_name = column[0]\n",
    "      col_type = column[1].split('(')[0]\n",
    "      col_nullable = column[2] == 'YES'\n",
    "      col_default = column[4]\n",
    "      \n",
    "      redshift_type = DATA_TYPE_MAP.get(col_type, \"VARCHAR\") # Default to VARCHAR if not found\n",
    "      \n",
    "      schema.append({\n",
    "          'name': col_name,\n",
    "          'type': redshift_type,\n",
    "          'nullable': col_nullable,\n",
    "          'default': col_default,\n",
    "      })\n",
    "\n",
    "    return schema\n",
    "\n",
    "def create_redshift_table(redshift_engine, table_name, schema):\n",
    "    \"\"\"Creates a table in Redshift based on the provided schema.\"\"\"\n",
    "    \n",
    "    columns_definition = []\n",
    "    for column in schema:\n",
    "      col_name = column['name']\n",
    "      col_type = column['type']\n",
    "      col_nullable = 'NULL' if column['nullable'] else 'NOT NULL'\n",
    "      col_default = f\"DEFAULT '{column['default']}'\" if column['default'] else ''\n",
    "      \n",
    "      columns_definition.append(f'\"{col_name}\" {col_type} {col_nullable} {col_default}'.strip())\n",
    "      \n",
    "    table_definition = ','.join(columns_definition)\n",
    "    create_table_sql = f'CREATE TABLE IF NOT EXISTS \"{table_name}\" ({table_definition});'\n",
    "\n",
    "    try:\n",
    "      with redshift_engine.connect() as connection:\n",
    "        connection.execute(text(create_table_sql))\n",
    "        logging.info(f'Table \"{table_name}\" created successfully in Redshift')\n",
    "    except SQLAlchemyError as e:\n",
    "        logging.error(f'Error creating table \"{table_name}\" in Redshift: {e}')\n",
    "        raise\n",
    "\n",
    "def migrate_table_data(mariadb_conn, redshift_engine, table_name):\n",
    "    \"\"\"Migrates data from a MariaDB table to Redshift.\"\"\"\n",
    "    logging.info(f'Migrating data for table \"{table_name}\"')\n",
    "\n",
    "    try:\n",
    "        mariadb_cursor = mariadb_conn.cursor(dictionary=True) #fetch rows as dict\n",
    "        mariadb_cursor.execute(f\"SELECT * FROM `{table_name}`\")\n",
    "\n",
    "        while True:\n",
    "          rows = mariadb_cursor.fetchmany(CHUNK_SIZE)\n",
    "          if not rows:\n",
    "              break\n",
    "\n",
    "          df = pd.DataFrame(rows)\n",
    "            \n",
    "          # Convert columns with datetime object to string \n",
    "          for col in df.columns:\n",
    "              if pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "                  df[col] = df[col].astype(str)\n",
    "          \n",
    "          df.to_sql(\n",
    "                table_name,\n",
    "                redshift_engine,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "                method='multi',\n",
    "                chunksize=CHUNK_SIZE,  \n",
    "            )\n",
    "          \n",
    "          logging.info(f'Inserted {len(rows)} rows into table \"{table_name}\"')\n",
    "\n",
    "        mariadb_cursor.close()\n",
    "\n",
    "    except Exception as e:\n",
    "      logging.error(f'Error migrating data for table \"{table_name}\": {e}')\n",
    "      raise\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to orchestrate the database migration.\"\"\"\n",
    "    try:\n",
    "        mariadb_conn = get_mariadb_connection()\n",
    "        redshift_engine = get_redshift_engine()\n",
    "        \n",
    "        mariadb_tables = get_mariadb_tables(mariadb_conn)\n",
    "        \n",
    "        logging.info(f\"Found {len(mariadb_tables)} tables in MariaDB: {mariadb_tables}\")\n",
    "        \n",
    "        for table_name in mariadb_tables:\n",
    "          logging.info(f\"Processing table: {table_name}\")\n",
    "          \n",
    "          schema = get_mariadb_table_schema(mariadb_conn, table_name)\n",
    "          create_redshift_table(redshift_engine, table_name, schema)\n",
    "          migrate_table_data(mariadb_conn, redshift_engine, table_name)\n",
    "          \n",
    "          logging.info(f\"Migration finished for {table_name}\")\n",
    "        \n",
    "        logging.info('Database migration completed successfully')\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Migration failed: {e}\")\n",
    "\n",
    "    finally:\n",
    "        if 'mariadb_conn' in locals() and mariadb_conn.is_connected():\n",
    "            mariadb_conn.close()\n",
    "        if 'redshift_engine' in locals() and redshift_engine:\n",
    "            redshift_engine.dispose()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "**How to Use:**\n",
    "\n",
    "1.  **Set up Environment Variables:** Create a `.env` file in the same directory as your Python script and fill in your database details:\n",
    "    ```\n",
    "    MARIADB_HOST=your_mariadb_host\n",
    "    MARIADB_USER=your_mariadb_user\n",
    "    MARIADB_PASSWORD=your_mariadb_password\n",
    "    MARIADB_DATABASE=your_mariadb_database\n",
    "\n",
    "    REDSHIFT_HOST=your_redshift_host\n",
    "    REDSHIFT_USER=your_redshift_user\n",
    "    REDSHIFT_PASSWORD=your_redshift_password\n",
    "    REDSHIFT_DATABASE=your_redshift_database\n",
    "    REDSHIFT_PORT=5439  # Default Redshift port\n",
    "    ```\n",
    "2.  **Install Dependencies:** `pip install mysql-connector-python psycopg2-binary boto3 pandas sqlalchemy python-dotenv tqdm`\n",
    "3.  **Run the script:** `python your_script_name.py`\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "1.  **Configuration:**\n",
    "    *   Loads database credentials and settings from environment variables using `dotenv`.\n",
    "    *   Defines global constants like `CHUNK_SIZE`.\n",
    "    *   Sets up basic logging for progress and errors.\n",
    "    *   Defines data type mapping from MariaDB to Redshift.\n",
    "\n",
    "2.  **Connection Functions:**\n",
    "    *   `get_mariadb_connection()`: Creates a connection to your MariaDB database using `mysql.connector`.\n",
    "    *   `get_redshift_engine()`: Creates a SQLAlchemy engine for Redshift using `psycopg2`.\n",
    "\n",
    "3.  **Schema Handling Functions:**\n",
    "    *   `get_mariadb_tables()`: Gets a list of tables in MariaDB using `SHOW TABLES`.\n",
    "    *   `get_mariadb_table_schema()`: Gets the column definitions (name, data type, nullability, etc.) using `SHOW COLUMNS`. It uses the `DATA_TYPE_MAP` to translate MariaDB types to appropriate Redshift types.\n",
    "    *   `create_redshift_table()`: Creates tables in Redshift using a constructed `CREATE TABLE` query with SQLAlchemy.\n",
    "\n",
    "4.  **Data Migration Functions:**\n",
    "    *   `migrate_table_data()`:\n",
    "        *   Fetches data in batches using `fetchmany` with specified `CHUNK_SIZE`.\n",
    "        *   Uses `pandas` to convert the data into dataframes and convert datetime objects to string.\n",
    "        *   Uses `pandas.to_sql()` to efficiently insert data into Redshift.\n",
    "\n",
    "5.  **Main Function:**\n",
    "    *   Orchestrates all steps: gets connections, lists tables, processes each table: gets schema, creates the table, and migrates the data.\n",
    "    *   Handles errors with a `try/except` block.\n",
    "    *   Closes connections in a `finally` block to release resources.\n",
    "\n",
    "**Important Notes:**\n",
    "\n",
    "*   **Large Databases:** For very large tables, you might need to explore more advanced techniques:\n",
    "    *   **AWS DMS:** Consider using AWS Database Migration Service (DMS) for a more robust and feature-rich approach.\n",
    "    *   **S3 Staging:** You could extract data from MariaDB into CSV files, upload them to S3, and then use Redshift's `COPY` command to ingest them (faster for large datasets).\n",
    "*   **Data Type Mapping:** The provided `DATA_TYPE_MAP` is a starting point. Carefully review your database schema and adjust it as needed for full compatibility with Redshift.\n",
    "*   **Error Handling:** The script includes basic error handling. You may need to add more fine-grained checks and logging based on your requirements.\n",
    "*   **Performance Tuning:** Experiment with the `CHUNK_SIZE` and consider using larger instance types for Redshift to optimize migration speed.\n",
    "*   **Permissions:** Make sure that your AWS credentials used by `boto3` have the necessary permissions to access Redshift and create tables. Your user should also have permissions on MariaDB to perform the queries.\n",
    "*   **Production Use:** This script should be thoroughly tested in a development or staging environment before running it in production.\n",
    "*   **Complex Schema:** For extremely complex schemas with foreign keys, constraints, etc. consider using an ETL tool or other more feature-rich solutions.\n",
    "\n",
    "This script provides a solid foundation for migrating data from MariaDB to Redshift Serverless. Please adjust and enhance it based on your specific needs and data requirements. Remember to always back up your data before performing any major migrations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
